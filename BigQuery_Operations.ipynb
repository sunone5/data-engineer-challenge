{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2e1162-dc42-42ef-91b4-ab18588a845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5279f86-632b-4524-82f0-542bf2ba64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.6\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c71595-344a-4a59-a98b-54419dcac932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4b389-a3b0-4d83-8bf8-5190b5d096c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3272bf-b690-4989-ae0c-f1c35f507690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8041ab5-b48e-4398-b0a8-9ca4eed94cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip show google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412e35b-a595-4a12-a2c5-1cb7fdd96576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip show python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bc632-fb1b-4dfb-8c75-e331a0b9a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip show pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521d63de-7fc4-4071-a0d7-81ba6e415c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9902ac59-2ee3-418e-8ccc-2b1f1b0c3c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030e00cb-a904-4d09-bae4-88aa73d6e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'bigquery-project-32089'\n",
    "dataset_id = 'customers_dataset'\n",
    "table_id = 'customers'\n",
    "dataset_full_name = f\"{project_id}.{dataset_id}\"\n",
    "table_full_name = f\"{project_id}.{dataset_id}.{table_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e417cd67-255a-479c-8901-ccf781fd595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505c2d5e-6648-4613-9500-7c646dd6f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_id):\n",
    "    dataset_ref = bigquery.DatasetReference.from_string(dataset_id, default_project=client.project)\n",
    "    dataset = bigquery.Dataset(dataset_ref)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = client.create_dataset(dataset)\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef8fcd0-ee4b-44fd-9ca1-783ffeaa3f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset bigquery-project-32089.customers_dataset\n"
     ]
    }
   ],
   "source": [
    "create_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038d2dec-9a81-4c02-9ded-73c76568417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets():\n",
    "    datasets = list(client.list_datasets())\n",
    "    project = client.project\n",
    "\n",
    "    if datasets:\n",
    "        print(\"Datasets in project {}:\".format(project))\n",
    "        for dataset in datasets:\n",
    "            print(\"\\t{}\".format(dataset.dataset_id))\n",
    "    else:\n",
    "        print(\"{} project does not contain any datasets.\".format(project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34bcc9c-8c3b-4643-bc06-bc54687fff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bigquery-project-32089:\n",
      "\tcustomer_dataset\n",
      "\tcustomers_dataset\n"
     ]
    }
   ],
   "source": [
    "# List available datasets\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4065dd-fe9a-4f90-ad70-ff9780c54dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a table in Python and load the data into it.\n",
    "def create_table(tablefullname):    \n",
    "    table_id = Table.from_string(tablefullname)\n",
    "\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"index\", \"INTEGER\", mode=\"NULLABLE\"),        \n",
    "    bigquery.SchemaField(\"guid\", \"STRING\", mode=\"NULLABLE\"),        \n",
    "    bigquery.SchemaField(\"isActive\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"age\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"eyeColor\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"gender\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"company\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"phone\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"address\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"about\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"registered\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"latitude\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"longitude\", \"FLOAT\", mode=\"NULLABLE\"), \n",
    "   \n",
    "    bigquery.SchemaField(\"tags\", \"STRING\", mode=\"REPEATED\"),\n",
    "        \n",
    "    bigquery.SchemaField(\n",
    "        \"friends\",\n",
    "        \"RECORD\",\n",
    "        mode=\"REPEATED\",\n",
    "        fields=[\n",
    "            bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            ],\n",
    "        ),\n",
    "        \n",
    "    bigquery.SchemaField(\"greeting\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"favoriteFruit\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    \n",
    "    ]  \n",
    "    \n",
    "\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "    table = client.create_table(table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd1346c3-c74b-4e3c-8a5c-d7a1642cbde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bigquery-project-32089.customers_dataset.customers\n"
     ]
    }
   ],
   "source": [
    "create_table(table_full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21329632-14fb-4032-b30e-4594ee682165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rows(tablefullname,json):    \n",
    "    table_id = Table.from_string(tablefullname)    \n",
    "    \n",
    "    errors = client.insert_rows_json(table_id, json)\n",
    "    if errors == []:\n",
    "        print(\"New rows have been added.\")\n",
    "    else:\n",
    "        print(\"Encountered errors while inserting rows: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7fcaf90-ec5e-46bb-810e-b4ba70342611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customers_1.json file\n",
    "import json\n",
    "# Define a string of json data\n",
    "customers_1_json_file = '.\\data\\customers_1.json'\n",
    "customers_1_json_data = [json.loads(line) for line in open(customers_1_json_file, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ae921e-0ea9-40fa-91b4-dadc8590d72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows have been added.\n"
     ]
    }
   ],
   "source": [
    "# Insert rows into table\n",
    "insert_rows(table_full_name,customers_1_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be56401e-bd63-4098-a232-c582f43b2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customers_2.json file has additional fields. Table needs to be updated for the schema change.\n",
    "customers_2_json_file = '.\\data\\customers_2.json'\n",
    "customers_2_json_data = [json.loads(line) for line in open(customers_2_json_file, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33687679-10c6-431f-8f89-81fc91110461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_schema_insert_fields(project_id,dataset_id,table_id,customers_2_json):   \n",
    "    project = client.project\n",
    "    dataset_ref = bigquery.DatasetReference(project, dataset_id)    \n",
    "\n",
    "    # Retrieves the destination table and checks the length of the schema    \n",
    "    table_ref = dataset_ref.table(table_id)\n",
    "    table = client.get_table(table_ref)\n",
    "    print(\"Table {} contains {} columns.\".format(table_id, len(table.schema)))\n",
    "    \n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=True,\n",
    "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "        schema_update_options=[\n",
    "            bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION,\n",
    "            bigquery.SchemaUpdateOption.ALLOW_FIELD_RELAXATION\n",
    "        ],\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND\n",
    "    )    \n",
    "    \n",
    "    job_config.schema = [\n",
    "        bigquery.SchemaField(\"balance\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"picture\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    ]    \n",
    "        \n",
    "    job = client.load_table_from_json(customers_2_json_data, table_ref, location=\"US\", job_config=job_config)\n",
    "    \n",
    "    job.result()  # Waits for table load to complete.\n",
    "    print(\n",
    "        \"Loaded {} rows into {}:{}.\".format(\n",
    "            job.output_rows, dataset_id, table_ref.table_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Checks the updated length of the schema\n",
    "    table = client.get_table(table)\n",
    "    print(\"Table {} now contains {} columns.\".format(table_id, len(table.schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56bd6f0-2da2-4b22-8a18-ca1ac5c1e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table customers contains 20 columns.\n",
      "Loaded 4 rows into customers_dataset:customers.\n",
      "Table customers now contains 22 columns.\n"
     ]
    }
   ],
   "source": [
    "# Update table schema with new fields\n",
    "update_schema_insert_fields(project_id,dataset_id,table_id,customers_2_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935684cc-21a3-4b30-bc66-bd40c9568345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customers_3.json file that includes another schema change.\n",
    "customers_3_json_file = '.\\data\\customers_3.json'\n",
    "customers_3_json_data = [json.loads(line) for line in open(customers_3_json_file, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e50cdf09-be8e-4013-a71c-95a1dc243854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming insert can possible \n",
    "# 1.) Using Legacy Streaming API  OR  # 2.) Using BigQuery Storage Write API \n",
    "\n",
    "# 1.) Using Legacy Streaming API\n",
    "def streaming_insert_rows(tablefullname,json):    \n",
    "    table_id = Table.from_string(tablefullname)    \n",
    "\n",
    "    errors = client.insert_rows_json(table_id, json)\n",
    "    if errors == []:\n",
    "        print(\"New rows have been added.\")\n",
    "    else:\n",
    "        print(\"Encountered errors while inserting rows: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28bc8743-26a0-4efc-8a97-c73d8a7bbe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered errors while inserting rows: [{'index': 0, 'errors': [{'reason': 'invalid', 'location': 'foes', 'debugInfo': '', 'message': 'no such field: foes.'}]}, {'index': 1, 'errors': [{'reason': 'invalid', 'location': 'foes', 'debugInfo': '', 'message': 'no such field: foes.'}]}, {'index': 2, 'errors': [{'reason': 'invalid', 'location': 'foes', 'debugInfo': '', 'message': 'no such field: foes.'}]}, {'index': 3, 'errors': [{'reason': 'invalid', 'location': 'foes', 'debugInfo': '', 'message': 'no such field: foes.'}]}]\n"
     ]
    }
   ],
   "source": [
    "streaming_insert_rows(table_full_name,customers_3_json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a71d1-8e95-46cc-be02-9b74d16df49d",
   "metadata": {},
   "source": [
    "### As you can see from above example , when I try to execute above code, It will produce errors. Because customers_3.json file includes another schema change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1bcca-73d6-4613-b68d-a164e9abbad7",
   "metadata": {},
   "source": [
    "# Legacy Streaming API doesn't support schema update while appending new rows into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aa28aae-f025-4e2f-9546-7531df31c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution - Update table schema first and then use Legacy Streaming API calls again.\n",
    "def update_table_schema(tableid):\n",
    "    table = client.get_table(tableid)  \n",
    "\n",
    "    original_schema = table.schema\n",
    "    new_schema = original_schema[:]  # Creates a copy of the schema.\n",
    "    \n",
    "    # Append new fields to schema\n",
    "    new_schema.append(bigquery.SchemaField(\n",
    "        \"foes\",\n",
    "        \"RECORD\",\n",
    "        mode=\"REPEATED\",\n",
    "        fields=[\n",
    "            bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            ],\n",
    "        ))\n",
    "\n",
    "    # Update Table with new schema\n",
    "    table.schema = new_schema\n",
    "    table = client.update_table(table, [\"schema\"]) \n",
    "\n",
    "    if len(table.schema) == len(original_schema) + 1 == len(new_schema):\n",
    "        print(\"A new column has been added.\")\n",
    "    else:\n",
    "        print(\"The column has not been added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb6ce636-db5d-4525-9919-4d1e280a7113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new column has been added.\n"
     ]
    }
   ],
   "source": [
    "# Update table schema with new fields\n",
    "update_table_schema(table_full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fca4adaf-d049-4e3a-a2f0-96b757426a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Legacy Streaming API call again with json file that has additional fields.\n",
    "def streaming_insert_rows(tablefullname,json):    \n",
    "    table_id = Table.from_string(tablefullname)    \n",
    "\n",
    "    errors = client.insert_rows_json(table_id, json)\n",
    "    if errors == []:\n",
    "        print(\"New rows have been added.\")\n",
    "    else:\n",
    "        print(\"Encountered errors while inserting rows: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf31ea08-b2da-4c33-addb-133f6698c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows have been added.\n"
     ]
    }
   ],
   "source": [
    "# Call streaming_insert_rows() function again.\n",
    "streaming_insert_rows(table_full_name,customers_3_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd3e5f-2b4a-48a0-8f4e-fdb9df0f7e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
